import cv2
import depthai as dai
import numpy as np
import argparse
import time
import blobconverter
from infer import mirror
from sklearn.cluster import KMeans

NN_WIDTH, NN_HEIGHT = 256, 256

# --------------- Pipeline ---------------
# Start defining a pipeline
pipeline = dai.Pipeline()
pipeline.setOpenVINOVersion(version=dai.OpenVINO.VERSION_2021_4)

# Define a neural network
detection_nn = pipeline.create(dai.node.NeuralNetwork)
# detection_nn.setBlobPath(str(NN_PATH))
detection_nn.setBlobPath("../Models/blob/MiDaS_small.blob")

detection_nn.setNumPoolFrames(4)
detection_nn.input.setBlocking(False)
detection_nn.setNumInferenceThreads(2)

# Define camera
cam = pipeline.create(dai.node.ColorCamera)
cam.setPreviewSize(NN_WIDTH, NN_HEIGHT)
cam.setInterleaved(False)
cam.setFps(40)
cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)

# Create outputs
xout_cam = pipeline.create(dai.node.XLinkOut)
xout_cam.setStreamName("cam")

xout_nn = pipeline.create(dai.node.XLinkOut)
xout_nn.setStreamName("nn")

# Link
cam.preview.link(detection_nn.input)
detection_nn.passthrough.link(xout_cam.input)
detection_nn.out.link(xout_nn.input)

def palette(clusters):
    width=300
    palette = np.zeros((50, width, 3), np.uint8)
    steps = width/clusters.cluster_centers_.shape[0]
    for idx, centers in enumerate(clusters.cluster_centers_): 
        palette[:, int(idx*steps):(int((idx+1)*steps)), :] = centers
    return palette

# --------------- Inference ---------------
# Pipeline defined, now the device is assigned and pipeline is started
with dai.Device(pipeline) as device:

    # Output queues will be used to get the rgb frames and nn data from the outputs defined above
    q_cam = device.getOutputQueue("cam", 4, blocking=False)
    q_nn = device.getOutputQueue(name="nn", maxSize=4, blocking=False)

    start_time = time.time()
    counter = 0
    fps = 0
    layer_info_printed = False
    while True:
        in_frame = q_cam.get()
        in_nn = q_nn.get()

        frame1 = in_frame.getCvFrame()

        # Make a mirror mask on input image
        frame = mirror(frame1)

        # Invert the Mask
        inv_frame = cv2.bitwise_not(frame)

        # Get output layer of MiDaS
        pred = np.array(in_nn.getFirstLayerFp16()).reshape(
            (NN_HEIGHT, NN_WIDTH))

        # Scale depth to get relative depth
        d_min = np.min(pred)
        d_max = np.max(pred)
        depth_relative = (pred - d_min) / (d_max - d_min)

        # Color it
        depth_relative = np.array(depth_relative) * 255
        depth_relative = depth_relative.astype(np.uint8)
        depth_relative = cv2.applyColorMap(
            depth_relative, cv2.COLORMAP_INFERNO)

        # Downscale frame
        frame = cv2.resize(frame, (NN_WIDTH//2, NN_HEIGHT//2))

        # Threshold Mask values
        ret, thresh1 = cv2.threshold(inv_frame, 120, 255, cv2.THRESH_BINARY)

        # Convert GrayScale to RGB for Bitwise AND compatibility (same number of channels)
        backtorgb = cv2.cvtColor(thresh1, cv2.COLOR_GRAY2RGB)

        # Apply Bitwise AND to MiDas output(depth_relative) and (Mask generated by MirrorNet)
        final = cv2.bitwise_and(depth_relative, backtorgb)

        # Define Kernel for Dilation
        kernel = np.ones((5, 5), np.uint8)

        # Apply Image Dilation
        img_dilation = cv2.dilate(final, kernel, iterations=1)

        # Subtract Dilated from original
        sub = img_dilation-final

        # Extract palette
        clt_3 = KMeans(n_clusters=3)
        clt_3.fit(sub.reshape(-1, 3))
        fill_color = palette(clt_3)[-1][-1]
        # print(palette(clt_3)[-1][-1])

        # Replace holes (black spots) with custom color obtained by K Means
        final[np.where((final==[0,0,0]).all(axis=2))] = fill_color

        cv2.imshow("dilate",img_dilation)
        cv2.imshow("sub", sub)
        Hori = np.concatenate((depth_relative, backtorgb, final), axis=1)
        cv2.imshow("Detections", Hori)

        # Count FPS
        counter += 1
        if (time.time() - start_time) > 1:
            fps = counter / (time.time() - start_time)

            counter = 0
            start_time = time.time()
            print(fps)

        if cv2.waitKey(1) == ord('q'):
            break